{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "Qbdc4DLhisRW",
        "outputId": "1aac69e1-89be-488b-852d-f49e1386af85"
      },
      "source": [
        "#https://www.kaggle.com/c/nlp-243-f21-core-rel-pred/data?select=test_data.csv\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "\n",
        "corpus_entries = []\n",
        "with open('train_data_merged_labels.csv', 'r') as corpus_csv:\n",
        "  corpus_raw = pd.read_csv(corpus_csv)\n",
        "  #print(corpus_raw.loc[0])\n",
        "\n",
        "pipe = Pipeline([('count', CountVectorizer()),\n",
        "                 ('tfidf', TfidfTransformer())]).fit(corpus_raw['utterances'])\n",
        "\n",
        "x_vectorizer = CountVectorizer()\n",
        "nrmlzr = Normalizer()\n",
        "x = x_vectorizer.fit_transform(corpus_raw['utterances'])\n",
        "#x = nrmlzr.transform(x)\n",
        "#print(x.toarray())\n",
        "x_tvectorizer = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2',\n",
        "                                encoding='latin-1', ngram_range=(1,2), stop_words='english')\n",
        "#x = x_tvectorizer.fit_transform(corpus_raw['utterances'])\n",
        "#x = pipe.transform(corpus_raw['utterances'])\n",
        "\n",
        "y_binarizer = LabelBinarizer()\n",
        "y = y_binarizer.fit_transform(corpus_raw['Core Relations'])\n",
        "#print(y)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=7)\n",
        "\n",
        "scalar = StandardScaler(with_mean=False)\n",
        "x_train_scaled = scalar.fit_transform(x_train)\n",
        "x_test_scaled = scalar.transform(x_test)\n",
        "\n",
        "#print(len(y_train[0]))\n",
        "#oversample = RandomOverSampler(sampling_strategy='minority')\n",
        "#x_train, y_train = oversample.fit_resample(x_train, y_train)\n",
        "#print(len(y_train[0]))\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "dtc = DecisionTreeClassifier(class_weight='balanced', max_depth=140)\n",
        "dtc.fit(x_train_scaled, y_train)\n",
        "y_test_pred = dtc.predict(x_test_scaled)\n",
        "\n",
        "print(accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "lscv = LinearSVC(C=1.0)\n",
        "grid = GridSearchCV(lscv, param_grid, refit=True, verbose=0)\n",
        "ovr = OneVsRestClassifier(lscv)\n",
        "with warnings.catch_warnings():\n",
        "  warnings.simplefilter(\"ignore\")\n",
        "  ovr.fit(x_train, y_train)\n",
        "y_test_pred = ovr.predict(x_test)\n",
        "\n",
        "print(accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "cnb = ComplementNB()\n",
        "ovr2 = OneVsRestClassifier(cnb)\n",
        "with warnings.catch_warnings():\n",
        "  warnings.simplefilter(\"ignore\")\n",
        "  ovr2.fit(x_train, y_train)\n",
        "y_test_pred = ovr2.predict(x_test)\n",
        "\n",
        "print(accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "test_raw = pd.read_csv('test_data.csv')\n",
        "x_test_actual = x_vectorizer.transform(test_raw['utterances'])\n",
        "x_test_actual = scalar.transform(x_test_actual)\n",
        "y_actual_pred = ovr.predict(x_test_actual)\n",
        "\n",
        "d = {'Id': range(0, len(y_actual_pred)), 'Predicted': y_binarizer.inverse_transform(y_actual_pred)}\n",
        "df = pd.DataFrame(data=d)\n",
        "df.to_csv('predictions.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-15b506305ded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcorpus_entries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_data_merged_labels.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcorpus_csv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m   \u001b[0mcorpus_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;31m#print(corpus_raw.loc[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_data_merged_labels.csv'"
          ]
        }
      ]
    }
  ]
}